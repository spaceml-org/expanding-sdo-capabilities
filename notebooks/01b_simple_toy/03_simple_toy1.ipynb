{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Standard Candle\" Toy 3: Brightness MNIST\n",
    "\n",
    "Randomly adjust the brightness of each MNIST sample. The output of the network is still just the MNIST number label, not the brightness yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this notebook should be run from the `notebooks/` subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Change this to what the notebook name is for each experiment to ensure\n",
    "# training results are saved into the right sub-directory.\n",
    "notebook_name = '03b_simple_toy1'\n",
    "\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protective code to ensure we always reset the random seed when doing training, or else\n",
    "# code won't be reproducible.\n",
    "if 'training_runs_count' not in globals():\n",
    "  training_runs_count = 0\n",
    "if 'seed_reset_count' not in globals():\n",
    "  seed_reset_count = 0\n",
    "\n",
    "root_path = '../..' # Relative to: notebooks/01b_simple_toy\n",
    "data_path = os.path.join(root_path, 'data', notebook_name)\n",
    "results_path = os.path.join(root_path, 'training_results', notebook_name)\n",
    "model_path = os.path.join(results_path, 'model.pth')\n",
    "optimizer_path = os.path.join(results_path, 'optimizer.pth')\n",
    "\n",
    "for path in [data_path, results_path]:\n",
    "  if not os.path.exists(path):\n",
    "    print('{} does not exist; creating directory...'.format(os.path.abspath(path)))\n",
    "    os.makedirs(path)\n",
    "\n",
    "n_epochs = 8\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0 for training, current device: 0, total devices: 6\n"
     ]
    }
   ],
   "source": [
    "cuda_device = 0\n",
    "torch.backends.cudnn.enabled = True\n",
    "if not torch.cuda.is_available():\n",
    "  raise RuntimeError(\"CUDA not available! Unable to continue\")\n",
    "# Force ourselves to use only one GPU.\n",
    "device = torch.device(\"cuda:{}\".format(cuda_device))\n",
    "print(\"Using device {} for training, current device: {}, total devices: {}\".format(\n",
    "  device, torch.cuda.current_device(), torch.cuda.device_count()))\n",
    "\n",
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "seed_reset_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrightnessMNIST(torchvision.datasets.MNIST):\n",
    "  \n",
    "  # TODO: Use dynamic arguments to not have to hard code these params from torchvision.datsets.MNIST.\n",
    "  def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "    super(BrightnessMNIST, self).__init__(root, train, transform, target_transform, download)\n",
    "    self._precompute_brightness()\n",
    "    self._compute_statistics()\n",
    "    \n",
    "  def _precompute_brightness(self):\n",
    "    # Randomly compute what the brightness setting should be for each sample.\n",
    "    # NOTE: Below 30% brightness accuracy degrades vs. the experiment 2 baseline.\n",
    "    self._brightness = np.round((0.3 - 1.0) * np.random.random_sample((len(self.data),1)) + 1.0,\n",
    "                                decimals=2)\n",
    "\n",
    "  def _compute_statistics(self):\n",
    "    all_data = self.data.numpy()\n",
    "    max_pixel_value = 255.0\n",
    "    \n",
    "    # Apply our brightness to each sample image.\n",
    "    results = all_data * self._brightness[..., np.newaxis]\n",
    "    \n",
    "    self.global_mean = np.round(results.mean() / max_pixel_value, decimals=4)\n",
    "    self.global_std = np.round(results.std() / max_pixel_value, decimals=4)\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "    brightness = torch.tensor(self._brightness[index])\n",
    "    img = img.double().mul(brightness).byte()\n",
    "    # NOTE: If we don't cast back into a PIL Image we lose some precision vs. experiment 2; this is\n",
    "    # probably due to some image processing or slight byte conversion happening inside of PIL image.\n",
    "    img = Image.fromarray(img.numpy(), mode='L')\n",
    "    \n",
    "    if self.transform is not None:\n",
    "        img = self.transform(img)\n",
    "\n",
    "    if self.target_transform is not None:\n",
    "        target = self.target_transform(target)\n",
    "    \n",
    "    # TODO: Return the brightness_alpha along with the target values.\n",
    "    #     return (torch.from_numpy(img),\n",
    "    #             torch.from_numpy(np.array([target, brightness_alpha])))\n",
    "    return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed MNIST global mean over training data: 0.085\n",
      "Computed MNIST std over training data: 0.2114\n"
     ]
    }
   ],
   "source": [
    "# TODO: See if setting num_workers > 1 or using pin_memory can help with CPU/GPU transfers.\n",
    "\n",
    "training_data = BrightnessMNIST(data_path, train=True, download=True)\n",
    "\n",
    "print(\"Computed MNIST global mean over training data: {}\".format(training_data.global_mean))\n",
    "print(\"Computed MNIST std over training data: {}\".format(training_data.global_std))\n",
    "\n",
    "training_data.transform = transforms = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Normalize((training_data.global_mean,), (training_data.global_std,))\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size_train,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  BrightnessMNIST(data_path, train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((training_data.global_mean,), (training_data.global_std,))\n",
    "  ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)\n",
    "    self.conv2_drop = nn.Dropout2d()\n",
    "    self.fc1 = nn.Linear(in_features=320, out_features=50)\n",
    "    self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), kernel_size=2))\n",
    "    x = x.view(-1, 320)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.dropout(x, training=self.training)\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x)\n",
    "\n",
    "model = Net()\n",
    "model.cuda()\n",
    "\n",
    "# Use a second-order optimizer like Adam so that we don't need to deal with things\n",
    "# like learning rates and momentum.\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_losses, train_counter, test_losses = [], [], []\n",
    "test_counter = [i * len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "def train(epoch):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    output = output.to(device)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100.0 * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx * 64) + ((epoch - 1) * len(train_loader.dataset)))\n",
    "      torch.save(model.state_dict(), model_path)\n",
    "      torch.save(optimizer.state_dict(), optimizer_path)\n",
    "\n",
    "def test():\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data = data.to(device)\n",
    "      target = target.to(device)\n",
    "      output = model(data)\n",
    "      output = output.to(device)\n",
    "      # TODO: Handle the deprecation warning for log_softmax needing an explicit 'dim' argument\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100.0 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gpfs_gl4_16mb/b9p111/fdl_sw/conda/envs/wmlce_py3_sdo/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3306, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.345203\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.261012\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.094696\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 1.886992\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.753578\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.403919\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.354540\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.198246\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.137182\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.908500\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.203360\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.856718\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.838319\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.789575\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.585891\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.527466\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.767252\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.704162\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.713530\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.621493\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.694565\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.727464\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.506884\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.720288\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.458270\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.667253\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.581169\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.638895\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.424539\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.279353\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.474458\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.491403\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.562538\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.253921\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.478669\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.402657\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.546779\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.389750\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.373866\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.355005\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.705286\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.449945\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.457842\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.401631\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.583276\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.556589\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.370206\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.426599\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.408738\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.518619\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.229579\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.372954\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.582548\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.273706\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.378077\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.404729\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.450737\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.213488\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.357679\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.188750\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.431130\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.438170\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.215283\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.465599\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.295019\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.242740\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.483859\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.359727\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.466177\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.458017\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.346712\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.375901\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.429468\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.496596\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.193908\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.337868\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.273511\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.471152\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.347291\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.162919\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.393482\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.226988\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.457367\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.460870\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.389287\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.352559\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.365108\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.407833\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.212053\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.441227\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.222355\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.180724\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.226326\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.138137\n",
      "\n",
      "Test set: Avg. loss: 0.1177, Accuracy: 9653/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.293324\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.333552\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.394598\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.291970\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.536904\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.191806\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.283777\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.350303\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.300296\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.222682\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.265648\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.382638\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.226505\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.252716\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.210100\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.188946\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.279823\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.314598\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.211037\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.266705\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.236564\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.185126\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.336018\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.346424\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.275422\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.225975\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.211955\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.204293\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.275714\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.147312\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.182161\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.339174\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.476147\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.259882\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.320185\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.225970\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.327996\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.416062\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.311735\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.185802\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.104942\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.345124\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.169663\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.290440\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.403454\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.254888\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.116991\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.156707\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.296723\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.244078\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.169964\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.451031\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.143837\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.210169\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.245521\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.228777\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.167198\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.256272\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.366986\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.180092\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.458039\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.130734\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.196230\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.305821\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.460113\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.363185\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.195272\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.151304\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.521720\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.093077\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.213253\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.212033\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.313473\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.279167\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.187355\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.403150\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.191349\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.236658\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.349857\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.269996\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.231313\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.283683\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.169095\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.080337\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.393179\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.183596\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.249329\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.408756\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.330489\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.192206\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.124668\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.261224\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.511699\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.359822\n",
      "\n",
      "Test set: Avg. loss: 0.0818, Accuracy: 9771/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.251713\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.152199\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.189123\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.192280\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.199005\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.299320\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.154360\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.114675\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.312788\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.245320\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.168535\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.171724\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.117865\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.151019\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.287133\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.623767\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.320725\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.221740\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.100427\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.187049\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.195675\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.259917\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.264659\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.227172\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.345077\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.456338\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.290788\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.263013\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.361371\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.267625\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.258820\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.229353\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.299721\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.231171\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.321439\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.161848\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.305967\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.117617\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.092754\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.144067\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.310222\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.349858\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.062504\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.251654\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.189719\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.299601\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.542145\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.355048\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.153618\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.233073\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.178991\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.311746\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.136919\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.093747\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.427090\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.439223\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.264009\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.174379\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.135845\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.272993\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.483805\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.187685\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.110199\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.256420\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.179903\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.163473\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.194749\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.372325\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.277495\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.231295\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.492523\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.295680\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.205886\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.088118\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.233500\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.170209\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.089551\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.191183\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.103630\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.077962\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.145001\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.197869\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.086493\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.158680\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.083679\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.195285\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.146369\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.169395\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.166352\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.125378\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.211429\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.328579\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.150483\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.445968\n",
      "\n",
      "Test set: Avg. loss: 0.0615, Accuracy: 9820/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.172913\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.215289\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.203136\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.434407\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.175777\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.146449\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.319625\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.245922\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.233739\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.405456\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.123183\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.128094\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.208955\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.159622\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.101870\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.189878\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.266829\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.251257\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.077211\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.173629\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.160011\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.283127\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.174470\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.240295\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.075557\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.156228\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.181349\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.189195\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.094230\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.152980\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.323824\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.245968\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.110186\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.336791\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.092109\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.053677\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.151458\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.240684\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.120885\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.274421\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.202570\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.234596\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.269432\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.164605\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.096417\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.163592\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.131956\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.102902\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.149246\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.472460\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.236079\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.214135\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.227418\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.189511\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.336646\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.118688\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.281597\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.161069\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.077977\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.152427\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.069545\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.185815\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.163622\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.217133\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.118016\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.122690\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.147613\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.461759\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.275608\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.578171\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.155398\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.079847\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.196832\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.122597\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.234942\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.106320\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.161622\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.250463\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.177347\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.120368\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.169644\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.040808\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.391729\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.075968\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.062307\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.180283\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.212885\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.152456\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.183273\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.265435\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.187554\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.146954\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.449412\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.103210\n",
      "\n",
      "Test set: Avg. loss: 0.0611, Accuracy: 9820/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.215333\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.107188\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.588245\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.302775\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.143030\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.242255\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.333221\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.203926\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.182689\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.169320\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.102610\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.174130\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.140214\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.163047\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.163671\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.082478\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.099193\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.099596\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.176772\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.148623\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.124955\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.318951\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.153821\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.185881\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.061123\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.301752\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.246583\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.089267\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.306645\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.166967\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.129533\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.099765\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.305166\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.202553\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.149437\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.241111\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.176077\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.352751\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.088422\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.073967\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.301474\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.308520\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.299445\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.148387\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.139488\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.062999\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.190203\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.123696\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.130290\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.147848\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.257538\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.214681\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.302377\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.194741\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.080786\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.363983\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.129434\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.158414\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.101708\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.134785\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.191750\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.165296\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.307106\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.160402\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.280359\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.198060\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.274342\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.237879\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.135680\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.203978\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.218881\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.125644\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.314998\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.186517\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.155644\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.076108\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.075863\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.054010\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.095663\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.358813\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.222065\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.171202\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.230816\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.171825\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.115962\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.203949\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.222944\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.152386\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.084488\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.238477\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.281013\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.158805\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.081469\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.147039\n",
      "\n",
      "Test set: Avg. loss: 0.0543, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.106656\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.082405\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.202047\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.189698\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.181243\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.199195\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.281580\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.362087\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.124626\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.095116\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.110708\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.073083\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.142763\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.209885\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.163708\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.148955\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.157868\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.151539\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.131842\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.199060\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.077576\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.426024\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.184744\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.219643\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.207279\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.120778\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.079239\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.238858\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.020483\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.262826\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.262336\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.089417\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.114665\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.077666\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.095437\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.370148\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.131545\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.070929\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.128869\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.187613\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.125243\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.172122\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.114342\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.106919\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.184771\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.177091\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.147181\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.143468\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.205761\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.108449\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.047681\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.136575\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.114415\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.113651\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.367585\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.183117\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.205731\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.176979\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.192527\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.042455\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.115819\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.141122\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.124185\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.140222\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.066171\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.099329\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.302555\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.238532\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.188516\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.073874\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.068614\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.050926\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.171645\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.108640\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.036592\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.160799\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.079308\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.119394\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.078845\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.143385\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.291623\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.209687\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.240010\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.179049\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.091754\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.090462\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.093183\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.064643\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.172932\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.052304\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.050346\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.142375\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.106014\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.219039\n",
      "\n",
      "Test set: Avg. loss: 0.0505, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.111944\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.447515\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.220601\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.183436\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.177167\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.098903\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.130592\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.284792\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.064526\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.142759\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.083673\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.222202\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.223096\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.069566\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.154532\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.174790\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.179426\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.139663\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.436237\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.175532\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.155715\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.159218\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.211027\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.111501\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.060122\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.322023\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.088334\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.324321\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.344531\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.065208\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.163469\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.061399\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.159823\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.194487\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.087663\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.231783\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.192386\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.068605\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.117874\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.061167\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.133724\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.117087\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.082889\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.139774\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.175543\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.118462\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.246777\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.287508\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.161067\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.123344\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.181326\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.086546\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.515417\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.261053\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.131187\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.251301\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.159931\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.089289\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.158181\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.074521\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.165937\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.287769\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.145411\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.091739\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.147305\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.066344\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.192656\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.091423\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.284031\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.142227\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.170702\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.255929\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.101892\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.443865\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.030230\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.037463\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.188844\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.159028\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.092265\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.111679\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.214488\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.197993\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.165649\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.330517\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.138867\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.351146\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.051138\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.012419\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.244065\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.175542\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.133482\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.053676\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.042444\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.160220\n",
      "\n",
      "Test set: Avg. loss: 0.0464, Accuracy: 9870/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.128241\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.062999\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.216006\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.318936\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.166338\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.071592\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.101770\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.077859\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.107174\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.145496\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.283713\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.065420\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.170675\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.080379\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.176117\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.188587\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.148168\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.126395\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.401458\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.234165\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.060256\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.058253\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.084031\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.211402\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.098191\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.168183\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.102809\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.117429\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.100433\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.294560\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.054035\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.084877\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.238498\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.148305\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.116129\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.184515\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.053034\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.026672\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.039029\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.093028\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.180823\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.084284\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.227179\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.163481\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.187924\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.115201\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.087949\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.149412\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.149414\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.208259\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.117221\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.105565\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.089235\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.206757\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.262718\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.142537\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.034843\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.045845\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.177756\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.182655\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.214899\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.196935\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.062119\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.154938\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.117017\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.134911\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.171689\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.066717\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.506501\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.280541\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.077014\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.056900\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.073112\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.313882\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.122891\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.309517\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.143526\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.115412\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.135323\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.248357\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.166404\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.073722\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.198641\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.131188\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.147963\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.092257\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.122512\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.036296\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.221494\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.143795\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.061853\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.068992\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.212227\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.036808\n",
      "\n",
      "Test set: Avg. loss: 0.0440, Accuracy: 9872/10000 (98%)\n",
      "\n",
      "CPU times: user 2min 55s, sys: 1.03 s, total: 2min 56s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "# To ensure reproducibility, ensure we never attempt to train without also reseting the random seed every time.\n",
    "if training_runs_count >= seed_reset_count:\n",
    "  msg = \"You didn't reset the random seed! Runs won't be reproducible. Re-run reseting random seed.\"\n",
    "  raise Exception(msg)\n",
    "\n",
    "training_runs_count += 1\n",
    "\n",
    "def time_wrapper():\n",
    "  test()\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "%time time_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Best Results\n",
    "\n",
    "<b>03b_simple_toy1: Test set: Avg. loss: 0.0440, Accuracy: 9872/10000 (98%)</b><br/>\n",
    "<b>02b_simple_toy1: Test set: Avg. loss: 0.0393, Accuracy: 9870/10000 (98%)</b><br/>\n",
    "<b>01b_simple_toy1: Test set: Avg. loss: 0.0569, Accuracy: 9818/10000 (98%)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example With Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gpfs_gl4_16mb/b9p111/fdl_sw/conda/envs/wmlce_py3_sdo/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = model(example_data.to(device))\n",
    "  output = output.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training From Saved Checkpoint &amp; Final Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continued_network = Net()\n",
    "# continued_optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "#                                 momentum=momentum)\n",
    "\n",
    "# network_state_dict = torch.load(model_path)\n",
    "# continued_network.load_state_dict(network_state_dict)\n",
    "\n",
    "# optimizer_state_dict = torch.load(optimizer_path)\n",
    "# continued_optimizer.load_state_dict(optimizer_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def continue_training():\n",
    "#   for i in range(4, 9):\n",
    "#     test_counter.append(i*len(train_loader.dataset))\n",
    "#     train(i)\n",
    "#     test()\n",
    "\n",
    "# %time continue_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# plt.plot(train_counter, train_losses, color='blue')\n",
    "# plt.scatter(test_counter, test_losses, color='red')\n",
    "# plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "# plt.xlabel('number of training examples seen')\n",
    "# plt.ylabel('negative log likelihood loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
