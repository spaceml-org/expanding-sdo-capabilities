{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script we want to try to:\n",
    "    - use the trained generator to extract the latent representation\n",
    "    \n",
    "Taking inspiration from here https://github.com/spiorf/stylegan-encoder/blob/master/encode_images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/stylegan')\n",
    "sys.path.append('/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/stylegan-encoder')\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dnnlib\n",
    "import config\n",
    "import dnnlib.tflib as tflib\n",
    "from encoder.generator_model import Generator\n",
    "from encoder.perceptual_model import PerceptualModel\n",
    "\n",
    "%matplotlib inline\n",
    "PATH_GAN = '/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/results_styleGAN/00005-sgan-sdo-4gpu/network-snapshot-008040.pkl'\n",
    "PATH_PLOTS = '/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/results_styleGAN/plots'\n",
    "src_dir = '/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/datasets_styleGAN/sdo'\n",
    "generated_images_dir = '/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/results_styleGAN/generated_images'\n",
    "dlatent_dir = '/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/results_styleGAN/dlatent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_batches(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_images = [os.path.join(src_dir, x) for x in os.listdir(src_dir)]\n",
    "ref_images = list(filter(os.path.isfile, ref_images))\n",
    "\n",
    "if len(ref_images) == 0:\n",
    "    raise Exception('%s is empty' % args.src_dir)\n",
    "\n",
    "os.makedirs(generated_images_dir, exist_ok=True)\n",
    "os.makedirs(dlatent_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cbc589a57a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_GAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGs_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stylegan-encoder/encoder/generator_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, batch_size, randomize_noise)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlatent_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'learnable_dlatents'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dlatents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_dlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tflib.init_tf()\n",
    "batch_size = 1\n",
    "\n",
    "with open(PATH_GAN, 'rb') as pickle_file:\n",
    "    _, _, Gs_network = pickle.load(pickle_file)\n",
    "    generator = Generator(Gs_network, batch_size)\n",
    "    generated_images = generator.generate_images()\n",
    "    \n",
    "    generator = Generator(Gs_network, batch_size, randomize_noise=False)\n",
    "    perceptual_model = PerceptualModel(512, layer=9, batch_size=batch_size)\n",
    "    perceptual_model.build_perceptual_model(generator.generated_image)\n",
    "\n",
    "    # Optimize (only) dlatents by minimizing perceptual loss between reference and generated images in feature space\n",
    "    for images_batch in tqdm(split_to_batches(ref_images, args.batch_size), total=len(ref_images)//batch_size):\n",
    "        names = [os.path.splitext(os.path.basename(x))[0] for x in images_batch]\n",
    "\n",
    "        perceptual_model.set_reference_images(images_batch)\n",
    "        op = perceptual_model.optimize(generator.dlatent_variable)\n",
    "        pbar = tqdm(op)\n",
    "        for loss in pbar:\n",
    "            pbar.set_description(' '.join(names)+' Loss: %.2f' % loss)\n",
    "        print(' '.join(names), ' loss:', loss)\n",
    "\n",
    "        # Generate images from found dlatents and save them\n",
    "        generated_images = generator.generate_images()\n",
    "        generated_dlatents = generator.get_dlatents()\n",
    "        for img_array, dlatent, img_name in zip(generated_images, generated_dlatents, names):\n",
    "            img = PIL.Image.fromarray(img_array, 'RGB')\n",
    "            img.save(os.path.join(args.generated_images_dir, f'{img_name}.png'), 'PNG')\n",
    "            np.save(os.path.join(args.dlatent_dir, f'{img_name}.npy'), dlatent)\n",
    "\n",
    "        generator.reset_dlatents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
