{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to try the Pytorch BiGAN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from sdo.models.gan import Generator, Discriminator, Encoder\n",
    "from sdo.sdo_dataset import SDO_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "save_image_dir = '/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/results_BiGAN/plots'\n",
    "save_model_dir = '/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap/results_BiGAN/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a way to get nice logging messages from the sdo package\n",
    "logformat = \"[%(asctime)s] %(levelname)s:%(name)s:%(message)s\"\n",
    "logging.basicConfig(level=logging.DEBUG, stream=sys.stdout, format=logformat, datefmt=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "subsample = 1\n",
    "original_ratio = 512\n",
    "img_shape = int(original_ratio/subsample)\n",
    "instr = ['AIA', 'AIA', 'AIA']\n",
    "channels = ['0171', '0193', '0094']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:4 for training, current device: 0, total devices: 6\n"
     ]
    }
   ],
   "source": [
    "#some cuda initialization\n",
    "torch.backends.cudnn.enabled = True\n",
    "cuda_device = 4\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA not available! Unable to continue\")\n",
    "device = torch.device(\"cuda:{}\".format(cuda_device))\n",
    "print(\"Using device {} for training, current device: {}, total devices: {}\".format(\n",
    "device, torch.cuda.current_device(), torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-07-18 18:41:38] INFO:sdo.sdo_dataset:Loading SDOML from \"/gpfs/gpfs_gl4_16mb/b9p111/fdl_sw/SDOML\"\n",
      "[2019-07-18 18:41:38] INFO:sdo.sdo_dataset:Running on months \"[1 2 3 4 5 6 7 8]\"\n",
      "[2019-07-18 18:41:38] INFO:sdo.sdo_dataset:Number of SDO files = 2829\n",
      "[2019-07-18 18:41:38] INFO:sdo.sdo_dataset:Loading SDOML from \"/gpfs/gpfs_gl4_16mb/b9p111/fdl_sw/SDOML\"\n",
      "[2019-07-18 18:41:38] INFO:sdo.sdo_dataset:Running on months \"[10 11 12]\"\n",
      "[2019-07-18 18:41:38] INFO:sdo.sdo_dataset:Number of SDO files = 359\n"
     ]
    }
   ],
   "source": [
    "train_data = SDO_Dataset(device=device, instr=instr, channels=channels, yr_range=[2015, 2018], \n",
    "                         subsample=subsample, normalization=1, bytescaling=True)\n",
    "test_data = SDO_Dataset(device=device, instr=instr, channels=channels, yr_range=[2015, 2018], \n",
    "                        subsample=subsample, normalization=1, bytescaling=True, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "latent_size = 256\n",
    "num_epochs = 100\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are used in the original repo, do they make sense for us?\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def tocuda(x):\n",
    "    return x.cuda()\n",
    "\n",
    "def get_log_odds(raw_marginals):\n",
    "    marginals = torch.clamp(raw_marginals.mean(dim=0), 1e-7, 1 - 1e-7)\n",
    "    return torch.log(marginals / (1 - marginals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "netE = tocuda(Encoder(latent_size, noise=True))\n",
    "netG = tocuda(Generator(latent_size))\n",
    "# I think the output size should be 1 (real or fake)\n",
    "netD = tocuda(Discriminator(latent_size, dropout=0.2, output_size=1))\n",
    "\n",
    "netE.apply(weights_init)\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# what are betas?? is the value reasonable for our use-case?\n",
    "\n",
    "optimizerG = optim.Adam([{'params' : netE.parameters()},\n",
    "                         {'params' : netG.parameters()}], lr=lr, betas=(0.5,0.999))\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# this is Binary Cross Entropy\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch n 0\n",
      "Processing batch n 1\n",
      "Processing batch n 2\n",
      "Processing batch n 3\n",
      "Processing batch n 4\n",
      "Processing batch n 5\n",
      "Processing batch n 6\n",
      "Processing batch n 7\n",
      "Processing batch n 8\n",
      "Processing batch n 9\n",
      "Processing batch n 10\n",
      "Processing batch n 11\n",
      "Processing batch n 12\n",
      "Processing batch n 13\n",
      "Processing batch n 14\n",
      "Processing batch n 15\n",
      "Processing batch n 16\n",
      "Processing batch n 17\n",
      "Processing batch n 18\n",
      "Processing batch n 19\n",
      "Processing batch n 20\n",
      "Processing batch n 21\n",
      "Processing batch n 22\n",
      "Processing batch n 23\n",
      "Processing batch n 24\n",
      "Processing batch n 25\n",
      "Processing batch n 26\n",
      "Processing batch n 27\n",
      "Processing batch n 28\n",
      "Processing batch n 29\n",
      "Processing batch n 30\n",
      "Processing batch n 31\n",
      "Processing batch n 32\n",
      "Processing batch n 33\n",
      "Processing batch n 34\n",
      "Processing batch n 35\n",
      "Processing batch n 36\n",
      "Processing batch n 37\n",
      "Processing batch n 38\n",
      "Processing batch n 39\n",
      "Processing batch n 40\n",
      "Processing batch n 41\n",
      "Processing batch n 42\n",
      "Processing batch n 43\n",
      "Processing batch n 44\n",
      "Processing batch n 45\n",
      "Processing batch n 46\n",
      "Processing batch n 47\n",
      "Processing batch n 48\n",
      "Processing batch n 49\n",
      "Processing batch n 50\n",
      "Processing batch n 51\n",
      "Processing batch n 52\n",
      "Processing batch n 53\n",
      "Processing batch n 54\n",
      "Processing batch n 55\n",
      "Processing batch n 56\n",
      "Processing batch n 57\n",
      "Processing batch n 58\n",
      "Processing batch n 59\n",
      "Processing batch n 60\n",
      "Processing batch n 61\n",
      "Processing batch n 62\n",
      "Processing batch n 63\n",
      "Processing batch n 64\n",
      "Processing batch n 65\n",
      "Processing batch n 66\n",
      "Processing batch n 67\n",
      "Processing batch n 68\n",
      "Processing batch n 69\n",
      "Processing batch n 70\n",
      "Processing batch n 71\n",
      "Processing batch n 72\n",
      "Processing batch n 73\n",
      "Processing batch n 74\n",
      "Processing batch n 75\n",
      "Processing batch n 76\n",
      "Processing batch n 77\n",
      "Processing batch n 78\n",
      "Processing batch n 79\n",
      "Processing batch n 80\n",
      "Processing batch n 81\n",
      "Processing batch n 82\n",
      "Processing batch n 83\n",
      "Processing batch n 84\n",
      "Processing batch n 85\n",
      "Processing batch n 86\n",
      "Processing batch n 87\n",
      "Processing batch n 88\n",
      "Processing batch n 89\n",
      "Processing batch n 90\n",
      "Processing batch n 91\n",
      "Processing batch n 92\n",
      "Processing batch n 93\n",
      "Processing batch n 94\n",
      "Processing batch n 95\n",
      "Processing batch n 96\n",
      "Processing batch n 97\n",
      "Processing batch n 98\n",
      "Processing batch n 99\n",
      "Processing batch n 100\n",
      "Processing batch n 101\n",
      "Processing batch n 102\n",
      "Processing batch n 103\n",
      "Processing batch n 104\n",
      "Processing batch n 105\n",
      "Processing batch n 106\n",
      "Processing batch n 107\n",
      "Processing batch n 108\n",
      "Processing batch n 109\n",
      "Processing batch n 110\n",
      "Processing batch n 111\n",
      "Processing batch n 112\n",
      "Processing batch n 113\n",
      "Processing batch n 114\n",
      "Processing batch n 115\n",
      "Processing batch n 116\n",
      "Processing batch n 117\n",
      "Processing batch n 118\n",
      "Processing batch n 119\n",
      "Processing batch n 120\n",
      "Processing batch n 121\n",
      "Processing batch n 122\n",
      "Processing batch n 123\n",
      "Processing batch n 124\n",
      "Processing batch n 125\n",
      "Processing batch n 126\n",
      "Processing batch n 127\n",
      "Processing batch n 128\n",
      "Processing batch n 129\n",
      "Processing batch n 130\n",
      "Processing batch n 131\n",
      "Processing batch n 132\n",
      "Processing batch n 133\n",
      "Processing batch n 134\n",
      "Processing batch n 135\n",
      "Processing batch n 136\n",
      "Processing batch n 137\n",
      "Processing batch n 138\n",
      "Processing batch n 139\n",
      "Processing batch n 140\n",
      "Processing batch n 141\n",
      "Processing batch n 142\n",
      "Processing batch n 143\n",
      "Processing batch n 144\n",
      "Processing batch n 145\n",
      "Processing batch n 146\n",
      "Processing batch n 147\n",
      "Processing batch n 148\n",
      "Processing batch n 149\n",
      "Processing batch n 150\n",
      "Processing batch n 151\n",
      "Processing batch n 152\n",
      "Processing batch n 153\n",
      "Processing batch n 154\n",
      "Processing batch n 155\n",
      "Processing batch n 156\n",
      "Processing batch n 157\n",
      "Processing batch n 158\n",
      "Processing batch n 159\n",
      "Processing batch n 160\n",
      "Processing batch n 161\n",
      "Processing batch n 162\n",
      "Processing batch n 163\n",
      "Processing batch n 164\n",
      "Processing batch n 165\n",
      "Processing batch n 166\n",
      "Processing batch n 167\n",
      "Processing batch n 168\n",
      "Processing batch n 169\n",
      "Processing batch n 170\n",
      "Processing batch n 171\n",
      "Processing batch n 172\n",
      "Processing batch n 173\n",
      "Processing batch n 174\n",
      "Processing batch n 175\n",
      "Processing batch n 176\n",
      "Processing batch n 177\n",
      "Processing batch n 178\n",
      "Processing batch n 179\n",
      "Processing batch n 180\n",
      "Processing batch n 181\n",
      "Processing batch n 182\n",
      "Processing batch n 183\n",
      "Processing batch n 184\n",
      "Processing batch n 185\n",
      "Processing batch n 186\n",
      "Processing batch n 187\n",
      "Processing batch n 188\n",
      "Processing batch n 189\n",
      "Processing batch n 190\n",
      "Processing batch n 191\n",
      "Processing batch n 192\n",
      "Processing batch n 193\n",
      "Processing batch n 194\n",
      "Processing batch n 195\n",
      "Processing batch n 196\n",
      "Processing batch n 197\n",
      "Processing batch n 198\n",
      "Processing batch n 199\n",
      "Processing batch n 200\n",
      "Processing batch n 201\n",
      "Processing batch n 202\n",
      "Processing batch n 203\n",
      "Processing batch n 204\n",
      "Processing batch n 205\n",
      "Processing batch n 206\n",
      "Processing batch n 207\n",
      "Processing batch n 208\n",
      "Processing batch n 209\n",
      "Processing batch n 210\n",
      "Processing batch n 211\n",
      "Processing batch n 212\n",
      "Processing batch n 213\n",
      "Processing batch n 214\n",
      "Processing batch n 215\n",
      "Processing batch n 216\n",
      "Processing batch n 217\n",
      "Processing batch n 218\n",
      "Processing batch n 219\n",
      "Processing batch n 220\n",
      "Processing batch n 221\n",
      "Processing batch n 222\n",
      "Processing batch n 223\n",
      "Processing batch n 224\n",
      "Processing batch n 225\n",
      "Processing batch n 226\n",
      "Processing batch n 227\n",
      "Processing batch n 228\n",
      "Processing batch n 229\n",
      "Processing batch n 230\n",
      "Processing batch n 231\n",
      "Processing batch n 232\n",
      "Processing batch n 233\n",
      "Processing batch n 234\n",
      "Processing batch n 235\n",
      "Processing batch n 236\n",
      "Processing batch n 237\n",
      "Processing batch n 238\n",
      "Processing batch n 239\n",
      "Processing batch n 240\n",
      "Processing batch n 241\n",
      "Processing batch n 242\n",
      "Processing batch n 243\n",
      "Processing batch n 244\n",
      "Processing batch n 245\n",
      "Processing batch n 246\n",
      "Processing batch n 247\n",
      "Processing batch n 248\n",
      "Processing batch n 249\n",
      "Processing batch n 250\n",
      "Processing batch n 251\n",
      "Processing batch n 252\n",
      "Processing batch n 253\n",
      "Processing batch n 254\n",
      "Processing batch n 255\n",
      "Processing batch n 256\n",
      "Processing batch n 257\n",
      "Processing batch n 258\n",
      "Processing batch n 259\n",
      "Processing batch n 260\n",
      "Processing batch n 261\n",
      "Processing batch n 262\n",
      "Processing batch n 263\n",
      "Processing batch n 264\n",
      "Processing batch n 265\n",
      "Processing batch n 266\n",
      "Processing batch n 267\n",
      "Processing batch n 268\n",
      "Processing batch n 269\n",
      "Processing batch n 270\n",
      "Processing batch n 271\n",
      "Processing batch n 272\n",
      "Processing batch n 273\n",
      "Processing batch n 274\n",
      "Processing batch n 275\n",
      "Processing batch n 276\n",
      "Processing batch n 277\n",
      "Processing batch n 278\n",
      "Processing batch n 279\n",
      "Processing batch n 280\n",
      "Processing batch n 281\n",
      "Processing batch n 282\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'd_fake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c0b46fa6eb77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%s/netD_epoch_%d.pth'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msave_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mvutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%s/fake_%d.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msave_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd_fake' is not defined"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "        print(\"Processing batch n %d\" % batch_index)\n",
    "        real_label = Variable(tocuda(torch.ones(batch_size)))\n",
    "        fake_label = Variable(tocuda(torch.zeros(batch_size)))\n",
    "\n",
    "        noise1 = Variable(tocuda(torch.Tensor(data.size()).normal_(0, 0.1 * (num_epochs - epoch) / num_epochs)))\n",
    "        noise2 = Variable(tocuda(torch.Tensor(data.size()).normal_(0, 0.1 * (num_epochs - epoch) / num_epochs)))\n",
    "\n",
    "        if epoch == 0 and batch_index == 0:\n",
    "            netG.output_bias.data = get_log_odds(tocuda(data))\n",
    "\n",
    "        if data.size()[0] != batch_size:\n",
    "            continue\n",
    "\n",
    "        d_real = Variable(tocuda(data))\n",
    "\n",
    "        z_fake = Variable(tocuda(torch.randn(batch_size, latent_size, 1, 1)))\n",
    "        d_fake = netG(z_fake)\n",
    "\n",
    "        z_real, _, _, _ = netE(d_real)\n",
    "        z_real = z_real.view(batch_size, -1)\n",
    "\n",
    "        mu, log_sigma = z_real[:, :latent_size], z_real[:, latent_size:]\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        epsilon = Variable(tocuda(torch.randn(batch_size, latent_size)))\n",
    "\n",
    "        output_z = mu + epsilon * sigma\n",
    "\n",
    "        output_real, _ = netD(d_real + noise1, output_z.view(batch_size, latent_size, 1, 1))\n",
    "        output_fake, _ = netD(d_fake + noise2, z_fake)\n",
    "\n",
    "        loss_d = criterion(output_real, real_label) + criterion(output_fake, fake_label)\n",
    "        loss_g = criterion(output_fake, real_label) + criterion(output_real, fake_label)\n",
    "\n",
    "        if loss_g.data[0] < 3.5:\n",
    "            optimizerD.zero_grad()\n",
    "            loss_d.backward(retain_graph=True)\n",
    "            optimizerD.step()\n",
    "\n",
    "        optimizerG.zero_grad()\n",
    "        loss_g.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if batch_index % 1 == 0:\n",
    "            print(\"Epoch :\", epoch, \"Iter :\", batch_index, \"D Loss :\", loss_d.data[0], \"G loss :\", loss_g.data[0],\n",
    "                  \"D(x) :\", output_real.mean().data[0], \"D(G(x)) :\", output_fake.mean().data[0])\n",
    "\n",
    "        if batch_index % 50 == 0:\n",
    "            vutils.save_image(d_fake.cpu().data[:16, ], '%s/fake.png' % (save_image_dir))\n",
    "            vutils.save_image(d_real.cpu().data[:16, ], '%s/real.png'% (save_image_dir))\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (save_model_dir, epoch))\n",
    "        torch.save(netE.state_dict(), '%s/netE_epoch_%d.pth' % (save_model_dir, epoch))\n",
    "        torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (save_model_dir, epoch))\n",
    "\n",
    "        vutils.save_image(d_fake.cpu().data[:16, ], '%s/fake_%d.png' % (save_image_dir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_index%1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
