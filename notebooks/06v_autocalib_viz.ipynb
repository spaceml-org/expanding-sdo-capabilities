{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying lo load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sdo.models.autocalibration1 import Autocalibration1\n",
    "from torch.utils.data import DataLoader\n",
    "from sdo.datasets.dimmed_sdo_dataset import DimmedSDO_Dataset\n",
    "from sdo.pytorch_utilities import init_gpu, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = '/gpfs/gpfs_gl4_16mb/b9p111/b9p111ap//pipeline_results/experiments_results/brad_experiment_20/0500_brad_experiment_20_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autocalibration1(\n",
       "  (_conv2d1): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (_conv2d2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (_fc1): Linear(in_features=21632, out_features=256, bias=True)\n",
       "  (_fc2): Linear(in_features=256, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_channels = 7\n",
    "scaled_height = 128\n",
    "scaled_width = 128\n",
    "\n",
    "model = Autocalibration1(input_shape=[num_channels, scaled_height, scaled_width],\n",
    "                         output_dim=num_channels)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(path_model)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the loaded model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = init_gpu()\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_test = 1\n",
    "tolerance = 0.05\n",
    "\n",
    "test_dataset = DimmedSDO_Dataset(num_channels,\n",
    "                                 instr=[\"AIA\"] * num_channels,\n",
    "                                 channels=[\n",
    "                                    \"0094\",\n",
    "                                    \"0131\",\n",
    "                                    \"0171\",\n",
    "                                    \"0193\",\n",
    "                                    \"0211\",\n",
    "                                    \"0304\",\n",
    "                                    \"0335\"\n",
    "                                 ],\n",
    "                                 yr_range=[2012, 2013],\n",
    "                                 mnt_step=1,\n",
    "                                 day_step=1,\n",
    "                                 h_step=6,\n",
    "                                 min_step=60,\n",
    "                                 resolution=512,\n",
    "                                 subsample=4,\n",
    "                                 normalization=0,\n",
    "                                 scaling=True,\n",
    "                                 norm_by_orig_img_max=False,\n",
    "                                 norm_by_dimmed_img_max=False,\n",
    "                                 return_random_dim=False,\n",
    "                                 min_alpha=0.01)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input = []\n",
    "all_gt_output = []\n",
    "all_output = []\n",
    "\n",
    "for batch_idx, (input_data, gt_output, _) in enumerate(test_loader):\n",
    "  input_data = input_data\n",
    "  gt_output = gt_output\n",
    "  output = model(input_data)\n",
    "  \n",
    "  input_data = input_data.detach().numpy()\n",
    "  output = output.detach().numpy()\n",
    "  gt_output = gt_output.detach().numpy()\n",
    "  \n",
    "  all_input.append(input_data)\n",
    "  all_gt_output.append(gt_output)\n",
    "  all_output.append(output)\n",
    "\n",
    "all_input = np.array(all_input)\n",
    "all_gt_output = np.array(all_gt_output)\n",
    "all_output = np.array(all_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009486209"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(all_gt_output - all_output).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy blindly from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'preprocess_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-61a8e98de7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msdo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecreate_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'preprocess_image'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "\n",
    "from sdo.viz.misc_functions import preprocess_image, recreate_image, save_image\n",
    "\n",
    "\n",
    "class CNNLayerVisualization():\n",
    "    \"\"\"\n",
    "        Produces an image that minimizes the loss of a convolution\n",
    "        operation for a specific layer and filter\n",
    "    \"\"\"\n",
    "    def __init__(self, model, selected_layer, selected_filter):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.selected_layer = selected_layer\n",
    "        self.selected_filter = selected_filter\n",
    "        self.conv_output = 0\n",
    "        # Create the folder to export images if not exists\n",
    "        if not os.path.exists('../generated'):\n",
    "            os.makedirs('../generated')\n",
    "\n",
    "    def hook_layer(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            # Gets the conv output of the selected filter (from selected layer)\n",
    "            self.conv_output = grad_out[0, self.selected_filter]\n",
    "        # Hook the selected layer\n",
    "        self.model[self.selected_layer].register_forward_hook(hook_function)\n",
    "\n",
    "    def visualise_layer_with_hooks(self):\n",
    "        # Hook the selected layer\n",
    "        self.hook_layer()\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                # x is not used after this point because it is only needed to trigger\n",
    "                # the forward hook function\n",
    "                x = layer(x)\n",
    "                # Only need to forward until the selected layer is reached\n",
    "                if index == self.selected_layer:\n",
    "                    # (forward hook function triggered)\n",
    "                    break\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = '../generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)\n",
    "\n",
    "    def visualise_layer_without_hooks(self):\n",
    "        # Process image and return variable\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                x = layer(x)\n",
    "                if index == self.selected_layer:\n",
    "                    # Only need to forward until the selected layer is reached\n",
    "                    # Now, x is the output of the selected layer\n",
    "                    break\n",
    "            # Here, we get the specific filter from the output of the convolution operation\n",
    "            # x is a tensor of shape 1x512x28x28.(For layer 17)\n",
    "            # So there are 512 unique filter outputs\n",
    "            # Following line selects a filter from 512 filters so self.conv_output will become\n",
    "            # a tensor of shape 28x28\n",
    "            self.conv_output = x[0, self.selected_filter]\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = '../generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
