{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to understand which are the median counts for pixel values of the EUV channels. The goal is to identify some costants by channel to be used for scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sdo.sdo_dataset import SDO_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a way to get nice logging messages from the sdo package\n",
    "logformat = \"[%(asctime)s] %(levelname)s:%(name)s:%(message)s\"\n",
    "logging.basicConfig(level=logging.DEBUG, stream=sys.stdout, format=logformat, datefmt=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = 1\n",
    "original_ratio = 512\n",
    "img_shape = int(original_ratio/subsample)\n",
    "instr = ['AIA', 'AIA', 'AIA']\n",
    "channels = ['0171', '0193', '0094']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:2 for training, current device: 0, total devices: 6\n"
     ]
    }
   ],
   "source": [
    "#some cuda initialization\n",
    "torch.backends.cudnn.enabled = True\n",
    "cuda_device = 2\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA not available! Unable to continue\")\n",
    "device = torch.device(\"cuda:{}\".format(cuda_device))\n",
    "print(\"Using device {} for training, current device: {}, total devices: {}\".format(\n",
    "device, torch.cuda.current_device(), torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below the mean and mean median values for the raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-07-19 17:26:34] INFO:sdo.sdo_dataset:Loading SDOML from \"/gpfs/gpfs_gl4_16mb/b9p111/fdl_sw/SDOML\"\n",
      "[2019-07-19 17:26:34] INFO:sdo.sdo_dataset:Running on months \"[1 2 3 4 5 6 7]\"\n",
      "[2019-07-19 17:26:34] INFO:sdo.sdo_dataset:Number of found timestamps = 1664\n",
      "[2019-07-19 17:26:34] INFO:sdo.sdo_dataset:Number of discarded timestamps = 72\n",
      "[2019-07-19 17:26:34] INFO:sdo.sdo_dataset:Number of SDO files = 4992\n",
      "[2019-07-19 17:26:34] WARNING:sdo.sdo_dataset:Shuffling is being applied, this will alter the time sequence.\n"
     ]
    }
   ],
   "source": [
    "train_data = SDO_Dataset(device=device, instr=instr, channels=channels, yr_range=[2011, 2018], \n",
    "                         mnt_step=1, day_step=1, h_step=25, min_step=61, subsample=subsample, \n",
    "                         test_ratio= 0.3, normalization=0, scaling=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "data_loader = DataLoader(train_data, batch_size=sample_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median over sample {'0171': 333.38197509765627, '0193': 380.20519302368166, '0094': 1.9156283044815063}\n",
      "Mean over sample {'0171': 455.10101501464845, '0193': 567.6971893310547, '0094': 3.0502363741397858}\n"
     ]
    }
   ],
   "source": [
    "mean = np.zeros(len(channels))\n",
    "median = np.zeros(len(channels))\n",
    "for batch_index, batch in enumerate(data_loader):\n",
    "    for i in range(sample_size):\n",
    "        item = batch[i,:,:,:].cpu().numpy()\n",
    "        for j, ch in enumerate(channels):\n",
    "            mean[j] += np.mean(item[j, :, :])\n",
    "            median[j] += np.median(item[j, :, :])\n",
    "    median = median/sample_size\n",
    "    mean = mean/sample_size\n",
    "    break\n",
    "print(\"Median over sample\", dict(zip(channels, median)))\n",
    "print(\"Mean over sample\", dict(zip(channels, mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below the mean and mean median values for the scaled images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The units used for scaling are the following\n",
    "AUNIT_BYCH = {'1600': 500.0, '1700': 7000.0, '0094': 10.0, '0131': 80.0, '0171': 2000.0,\n",
    "               '0193': 3000.0, '0211': 1000.0, '0304': 500.0, '0335': 80.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-07-19 17:28:36] INFO:sdo.sdo_dataset:Loading SDOML from \"/gpfs/gpfs_gl4_16mb/b9p111/fdl_sw/SDOML\"\n",
      "[2019-07-19 17:28:36] INFO:sdo.sdo_dataset:Running on months \"[1 2 3 4 5 6 7]\"\n",
      "[2019-07-19 17:28:37] INFO:sdo.sdo_dataset:Number of found timestamps = 1664\n",
      "[2019-07-19 17:28:37] INFO:sdo.sdo_dataset:Number of discarded timestamps = 72\n",
      "[2019-07-19 17:28:37] INFO:sdo.sdo_dataset:Number of SDO files = 4992\n",
      "[2019-07-19 17:28:37] WARNING:sdo.sdo_dataset:Shuffling is being applied, this will alter the time sequence.\n"
     ]
    }
   ],
   "source": [
    "scaled_train_data = SDO_Dataset(device=device, instr=instr, channels=channels, yr_range=[2011, 2018], \n",
    "                         mnt_step=1, day_step=1, h_step=25, min_step=61, subsample=subsample, \n",
    "                         test_ratio= 0.3, normalization=0, scaling=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 500\n",
    "scaled_data_loader = DataLoader(scaled_train_data, batch_size=sample_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Median over sample {'0171': 0.16778671279549598, '0193': 0.13025649194419384, '0094': 0.19687237605452537}\n",
      "Mean over sample {'0171': 0.23262306255102158, '0193': 0.19759163378179073, '0094': 0.32357423728704454}\n",
      "Mean Max over sample {'0171': 6.849643320798874, '0193': 6.164027611970901, '0094': 56.6010144405365}\n"
     ]
    }
   ],
   "source": [
    "mean = np.zeros(len(channels))\n",
    "mean_median = np.zeros(len(channels))\n",
    "mean_max = np.zeros(len(channels))\n",
    "for batch_index, batch in enumerate(scaled_data_loader):\n",
    "    for i in range(sample_size):\n",
    "        item = batch[i,:,:,:].cpu().numpy()\n",
    "        for j, ch in enumerate(channels):\n",
    "            mean[j] += np.mean(item[j, :, :])\n",
    "            mean_median[j] += np.median(item[j, :, :])\n",
    "            mean_max[j] += np.max(item[j, :, :])\n",
    "    mean_median = mean_median/sample_size\n",
    "    mean = mean/sample_size\n",
    "    mean_max = mean_max/sample_size                              \n",
    "    break\n",
    "print(\"Mean Median over sample\", dict(zip(channels, mean_median)))\n",
    "print(\"Mean over sample\", dict(zip(channels, mean)))\n",
    "print(\"Mean Max over sample\", dict(zip(channels, mean_max)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
