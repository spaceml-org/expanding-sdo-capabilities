{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to try an experiment with time prediction of the Sun. A model that contains encoder/decoder and LSTM is here defined but still unclear how to pass the SDO dataset (encoding decoding has to be applied by image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sdo.sdo_dataset import SDO_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sdo.models.encoder_decoder import AutoEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # TODO: Choose a better hidden_size.\n",
    "        # TODO: Choose more stacked num_layers\n",
    "        self.lstm = nn.LSTM(input_size=latent_dim, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=50, out_features=latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1]  # Keep only the output of the last iteration.\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a way to get nice logging messages from the sdo package\n",
    "logformat = \"[%(asctime)s] %(levelname)s:%(name)s:%(message)s\"\n",
    "logging.basicConfig(level=logging.DEBUG, stream=sys.stdout, format=logformat, datefmt=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start simple by considering one single channel\n",
    "# single channel has a bug in the data loader (one xextra dim is added)\n",
    "subsample = 1\n",
    "original_ratio = 512\n",
    "img_shape = int(original_ratio/subsample)\n",
    "instr = ['AIA', 'AIA']\n",
    "channels = ['0171', '0094']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:3 for training, current device: 0, total devices: 6\n"
     ]
    }
   ],
   "source": [
    "#some cuda initialization\n",
    "torch.backends.cudnn.enabled = True\n",
    "cuda_device = 3\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA not available! Unable to continue\")\n",
    "device = torch.device(\"cuda:{}\".format(cuda_device))\n",
    "print(\"Using device {} for training, current device: {}, total devices: {}\".format(\n",
    "device, torch.cuda.current_device(), torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-07-23 12:55:56] INFO:sdo.sdo_dataset:Loading SDOML from \"/gpfs/gpfs_gl4_16mb/b9p111/fdl_sw/SDOML\"\n",
      "[2019-07-23 12:55:56] INFO:sdo.sdo_dataset:Training on months \"[1 2 3 4 5 6 7]\"\n",
      "[2019-07-23 12:55:56] DEBUG:sdo.sdo_dataset:Timestamps requested values: \n",
      "[2019-07-23 12:55:56] DEBUG:sdo.sdo_dataset:Years: 2018\n",
      "[2019-07-23 12:55:56] DEBUG:sdo.sdo_dataset:Months: 1,2,3,4,5,6,7\n",
      "[2019-07-23 12:55:56] DEBUG:sdo.sdo_dataset:Days: 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31\n",
      "[2019-07-23 12:55:56] DEBUG:sdo.sdo_dataset:Hours: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23\n",
      "[2019-07-23 12:55:56] DEBUG:sdo.sdo_dataset:Minutes: 0,12,24,36,48\n",
      "[2019-07-23 12:55:56] INFO:sdo.sdo_dataset:Max number of timestamps: 26040\n",
      "[2019-07-23 12:55:59] INFO:sdo.sdo_dataset:Timestamps found in the inventory: 24515 (0.94)\n",
      "[2019-07-23 12:56:03] INFO:sdo.sdo_dataset:N timestamps discarded because channel is missing = 18 (0.00073)\n",
      "[2019-07-23 12:56:03] INFO:sdo.sdo_dataset:Selected timestamps = 24497\n",
      "[2019-07-23 12:56:03] INFO:sdo.sdo_dataset:N images = 48994\n",
      "CPU times: user 6.81 s, sys: 310 ms, total: 7.12 s\n",
      "Wall time: 7.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = SDO_Dataset(device=device, instr=instr, channels=channels, yr_range=[2018,2018], \n",
    "                         mnt_step=1, day_step=1, h_step=1, min_step=12, subsample=subsample, \n",
    "                         test_ratio=0.3, normalization=0, scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this module we want to define an encoder/decoder RNN architecture\n",
    "\"\"\"\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "\n",
    "class EncoderDecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a RNN that output the next image of a sequence of images.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape=[1, 512, 512], hidden_dim_fc=512, hidden_dim_lstm=50):\n",
    "        super(EncoderDecoderRNN, self).__init__()\n",
    "        num_channels = input_shape[0]\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        \n",
    "        self.dconv5 = nn.ConvTranspose2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.dconv4 = nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3)\n",
    "        self.dconv3 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.dconv2 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3)\n",
    "        self.dconv1 = nn.ConvTranspose2d(in_channels=32, out_channels=num_channels, kernel_size=3)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2, return_indices=True)\n",
    "        self.unpool = nn.MaxUnpool2d(2, 2)\n",
    "\n",
    "        sample_encoder_input = torch.zeros(input_shape)\n",
    "        sample_encoder_output = self._encoder(sample_encoder_input.unsqueeze(0))[0]\n",
    "        sample_encoder_output_dim = sample_encoder_output.nelement()\n",
    "\n",
    "        # TODO: Choose a better hidden_size.\n",
    "        # TODO: Choose more stacked num_layers.\n",
    "        self.lstm = nn.LSTM(input_size=sample_encoder_output_dim,\n",
    "                            hidden_size=hidden_dim_lstm, num_layers=1, batch_first=True)\n",
    "        self.lstm_fc = nn.Linear(in_features=hidden_dim_lstm,\n",
    "                                 out_features=sample_encoder_output_dim)\n",
    "        \n",
    "        self.lin1 = nn.Linear(sample_encoder_output_dim, hidden_dim_fc)\n",
    "        self.lin2 = nn.Linear(hidden_dim_fc, sample_encoder_output_dim)\n",
    "\n",
    "        print('Autoencoder architecture:')\n",
    "        print('Input shape: {}'.format(input_shape))\n",
    "        print('Input dim  : {}'.format(prod(input_shape)))\n",
    "        print('Encoded dim: {}'.format(sample_encoder_output_dim))\n",
    "        print('Hidden dim FC: {}'.format(hidden_dim_fc))\n",
    "        print('Learnable params: {}'.format(sum([p.numel() for p in self.parameters()])))\n",
    "\n",
    "    def _encoder(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x, indices1 = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x, indices2 = self.pool(x)\n",
    "        x = self.conv4(x)\n",
    "        x, indices3 = self.pool(x)\n",
    "        x = self.conv5(x)\n",
    "        x, indices4 = self.pool(x)\n",
    "        x = F.relu(x)\n",
    "        return x, indices1, indices2, indices3, indices4\n",
    "\n",
    "    def _decoder(self, x, indices1, indices2, indices3, indices4):\n",
    "        x = self.unpool(x, indices4)\n",
    "        x = self.dconv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.unpool(x, indices3)\n",
    "        x = self.dconv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.unpool(x, indices2)\n",
    "        x = self.dconv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.unpool(x, indices1)\n",
    "        x = self.dconv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dconv1(x)\n",
    "        x = torch.relu(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        x, indices1, indices2, indices3, indices4 = self._encoder(x)\n",
    "        Shap = x.shape\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.reshape(Shap)\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1]  # Keep only the output of the last iteration.\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        \n",
    "        x = self._decoder(x, indices1, indices2, indices3, indices4)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder architecture:\n",
      "Input shape: [1, 512, 512]\n",
      "Input dim  : 262144\n",
      "Encoded dim: 57600\n",
      "Hidden dim FC: 512\n",
      "Learnable params: 74136545\n"
     ]
    }
   ],
   "source": [
    "#let's define a RNN model\n",
    "model = EncoderDecoderRNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 3 # Number of time steps for each sequence to learn over\n",
    "batch_size = 1 # Number of independent sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are loading 2 channels, this is way we discard the first\n",
    "start = 0\n",
    "end = seq_len + 1\n",
    "x = torch.tensor([[train_data[idx][0].cpu().numpy() for idx in range(start, end)]])\n",
    "# Slice off final end step of sequence as the ground truth.\n",
    "gt_final_step = x.clone()[:, -1]\n",
    "x = x[:, 0:seq_len]\n",
    "x = x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "out = model(x)\n",
    "loss = loss_function(out, gt_final_step)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the shuffling in the data loader shuffling the order of the batches or inside the batch\n",
    "train_data_loader = DataLoader(train_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "model.cuda(cuda_device)\n",
    "len_data = train_data.__len__()\n",
    "log_interval = 10\n",
    "# for now I am training on a single year\n",
    "n_epochs = 4\n",
    "train_loss = []\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_index, batch in enumerate(train_data_loader):\n",
    "        data = batch.to(cuda_device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch = model(data)\n",
    "        loss = loss_function(recon_batch, data)\n",
    "        train_loss.append(float(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_index % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_index * len(data), len_data, \n",
    "                100.*(batch_index* len(data)) / len_data, \n",
    "                loss.item() / len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
