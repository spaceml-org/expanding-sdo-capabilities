{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #Use CUDA if it is available\n",
    "num_channels = 5 # Number of channels used as input\n",
    "batch_size = 4 # Batch size of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the training process and architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "  \n",
    "class NetCNN(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()\n",
    "        if (len(input_shape) != 3):\n",
    "            raise ValueError('Expecting an input_shape representing dimensions CxHxW')\n",
    "        self._input_channels = input_shape[0]\n",
    "        print('input_channels: {}'.format(self._input_channels))\n",
    "        self._conv2d1 = nn.Conv2d(in_channels=self._input_channels, out_channels=64, kernel_size=3)\n",
    "        self._conv2d2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self._cnn_output_dim = self._cnn(torch.zeros(input_shape).unsqueeze(0)).nelement()\n",
    "        print('cnn_output_dim: {}'.format(self._cnn_output_dim))\n",
    "        self._fc1 = nn.Linear(self._cnn_output_dim, 256)\n",
    "        self._fc2 = nn.Linear(256, output_dim)\n",
    "        \n",
    "    def _cnn(self, x):\n",
    "        x = self._conv2d1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = nn.MaxPool2d(kernel_size=3)(x)\n",
    "        x = self._conv2d2(x)\n",
    "        x = nn.MaxPool2d(kernel_size=3)(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_dim = x.shape[0]\n",
    "        x = self._cnn(x).view(batch_dim, -1)\n",
    "        x = self._fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self._fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class NetFF(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()\n",
    "        if (len(input_shape) != 3):\n",
    "            raise ValueError('Expecting an input_shape representing dimensions CxHxW')\n",
    "        self._input_channels = input_shape[0]\n",
    "        print('input_channels: {}'.format(self._input_channels))\n",
    "        self._input_dim = prod(input_shape)\n",
    "        print('input_dim: {}'.format(self._input_dim))\n",
    "        self._fc1 = nn.Linear(self._input_dim, 64)\n",
    "        self._fc2 = nn.Linear(64, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self._input_dim)\n",
    "        x = self._fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self._fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "def run_experiment(name, sun_maker_func, debug_out=False):\n",
    "    sun = sun_maker_func(num_channels)\n",
    "    sun_numpy = sun.cpu().numpy()\n",
    "\n",
    "    if debug_out:\n",
    "        for channel in sun_numpy:\n",
    "            plt.imshow(channel, norm=None, cmap='hot', vmin=sun_numpy.min(), vmax=sun_numpy.max())\n",
    "            plt.show()\n",
    "\n",
    "    model = NetCNN(input_shape=[num_channels, 28, 28], output_dim=num_channels)\n",
    "    model.cuda(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    losses = []\n",
    "    for b in range(1000):\n",
    "        data = torch.cat([sun_maker_func(num_channels=num_channels) for i in range(batch_size)]).view(batch_size, num_channels, 28, 28)\n",
    "        data_min, data_max = torch.min(data), torch.max(data)\n",
    "        dim_factors = torch.rand(batch_size, num_channels).view(batch_size,-1).to(device)\n",
    "  #       print(batch.shape)\n",
    "  #       print(dim_factors.shape)\n",
    "        dimmed_data = data.clone().to(device)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(num_channels):\n",
    "                dimmed_data[i, j] *= dim_factors[i, j]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(dimmed_data)\n",
    "        loss = nn.MSELoss()(output, dim_factors)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        if b % 10 == 0:\n",
    "            print('Current loss: {}'.format(float(loss)))\n",
    "            sample = data[0].cpu().numpy()\n",
    "            sample_dimmed = dimmed_data[0].cpu().numpy()\n",
    "\n",
    "            if debug_out:\n",
    "                for i, (channel, channel_dimmed) in enumerate(zip(sample, sample_dimmed)):\n",
    "                    fig = plt.figure()\n",
    "                    ax1 = fig.add_subplot(1, 3, 1)\n",
    "                    ax1.imshow(channel, norm=None, cmap='hot', vmin=data_min, vmax=data_max)\n",
    "                    ax2 = fig.add_subplot(1, 3, 2)\n",
    "                    ax2.imshow(channel_dimmed, norm=None, cmap='hot', vmin=data_min, vmax=data_max)\n",
    "                    ax3 = fig.add_subplot(1, 3, 3)\n",
    "                    ax3.imshow(channel_dimmed / float(output[0, i]), norm=None, cmap='hot', vmin=data_min, vmax=data_max)\n",
    "                    print('Channel: {} (left: original, middle: dimmed, right: undimmed)\\nDimming (true): {}, dimming (predicted): {}'.format(i, dim_factors[0, i], output[0, i]))\n",
    "                    plt.show()\n",
    "                dim_factors_numpy = dim_factors[0].view(-1).cpu().numpy()\n",
    "                plt.plot(dim_factors_numpy, label='Dimming factors (true)')\n",
    "                output_numpy = output[0].detach().view(-1).cpu().numpy()\n",
    "                plt.plot(output_numpy, label='Dimming factors (predicted)')\n",
    "                plt.legend()\n",
    "#               plt.show()\n",
    "\n",
    "    if debug_out:\n",
    "        plt.plot(losses, label='training loss')\n",
    "        plt.show()\n",
    "    print('Loss min: {}, max: {}, mean: {}'.format(min(losses), max(losses), np.mean(losses)))\n",
    "  \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times to run each experiment.\n",
    "experiments_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Experiment Run 1\n",
      "input_channels: 5\n",
      "cnn_output_dim: 512\n",
      "Current loss: 0.06945878267288208\n",
      "Current loss: 0.10288645327091217\n",
      "Current loss: 0.04781074449419975\n",
      "Current loss: 0.07125212997198105\n",
      "Current loss: 0.06296664476394653\n",
      "Current loss: 0.0307395551353693\n",
      "Current loss: 0.05215989798307419\n",
      "Current loss: 0.02524392679333687\n",
      "Current loss: 0.02532106637954712\n",
      "Current loss: 0.02208906039595604\n",
      "Current loss: 0.036692749708890915\n",
      "Current loss: 0.013757598586380482\n",
      "Current loss: 0.018774351105093956\n",
      "Current loss: 0.01527427602559328\n",
      "Current loss: 0.02152041718363762\n",
      "Current loss: 0.023287976160645485\n",
      "Current loss: 0.045846205204725266\n",
      "Current loss: 0.011740343645215034\n",
      "Current loss: 0.006949233822524548\n",
      "Current loss: 0.016401540488004684\n",
      "Current loss: 0.017253946512937546\n",
      "Current loss: 0.003684496507048607\n",
      "Current loss: 0.02394123375415802\n",
      "Current loss: 0.03119569644331932\n",
      "Current loss: 0.005005055107176304\n",
      "Current loss: 0.016194630414247513\n",
      "Current loss: 0.030886661261320114\n",
      "Current loss: 0.006295560859143734\n",
      "Current loss: 0.009983156807720661\n",
      "Current loss: 0.02114224247634411\n",
      "Current loss: 0.00784587673842907\n",
      "Current loss: 0.008500074967741966\n",
      "Current loss: 0.015088634565472603\n",
      "Current loss: 0.0201540719717741\n",
      "Current loss: 0.008162913843989372\n",
      "Current loss: 0.009486136958003044\n",
      "Current loss: 0.0052168662659823895\n",
      "Current loss: 0.0035188395995646715\n",
      "Current loss: 0.03857794404029846\n",
      "Current loss: 0.01630299910902977\n",
      "Current loss: 0.012174095027148724\n",
      "Current loss: 0.006739555858075619\n",
      "Current loss: 0.013238047249615192\n",
      "Current loss: 0.013444271869957447\n",
      "Current loss: 0.006152153015136719\n",
      "Current loss: 0.0294962041079998\n",
      "Current loss: 0.02876303531229496\n",
      "Current loss: 0.006296234671026468\n",
      "Current loss: 0.009010491892695427\n",
      "Current loss: 0.00881918054074049\n",
      "Current loss: 0.007954885251820087\n",
      "Current loss: 0.004764634650200605\n",
      "Current loss: 0.02645735815167427\n",
      "Current loss: 0.004718966316431761\n",
      "Current loss: 0.00515763321891427\n",
      "Current loss: 0.005159222986549139\n",
      "Current loss: 0.0027231406420469284\n",
      "Current loss: 0.0021743234246969223\n",
      "Current loss: 0.006337933242321014\n",
      "Current loss: 0.03072376549243927\n",
      "Current loss: 0.0071623241528868675\n",
      "Current loss: 0.0021963438484817743\n",
      "Current loss: 0.01640128716826439\n",
      "Current loss: 0.048122651875019073\n",
      "Current loss: 0.02070773020386696\n",
      "Current loss: 0.003508398775011301\n",
      "Current loss: 0.016964921727776527\n",
      "Current loss: 0.005116083659231663\n",
      "Current loss: 0.004691398702561855\n",
      "Current loss: 0.004126480780541897\n",
      "Current loss: 0.002166083548218012\n",
      "Current loss: 0.0036725408863276243\n",
      "Current loss: 0.002839541994035244\n",
      "Current loss: 0.0070038242265582085\n",
      "Current loss: 0.009025047533214092\n",
      "Current loss: 0.0016914710868149996\n",
      "Current loss: 0.0036684218794107437\n",
      "Current loss: 0.005273008719086647\n",
      "Current loss: 0.014342399314045906\n",
      "Current loss: 0.002684397157281637\n",
      "Current loss: 0.008183294907212257\n",
      "Current loss: 0.008664187975227833\n",
      "Current loss: 0.019740242511034012\n",
      "Current loss: 0.0036583312321454287\n",
      "Current loss: 0.005738831125199795\n",
      "Current loss: 0.008489685133099556\n",
      "Current loss: 0.007680459413677454\n",
      "Current loss: 0.0025792226660996675\n",
      "Current loss: 0.005514524411410093\n",
      "Current loss: 0.005085761193186045\n",
      "Current loss: 0.0018791299080476165\n",
      "Current loss: 0.004309049341827631\n",
      "Current loss: 0.0035752765834331512\n",
      "Current loss: 0.004253008868545294\n",
      "Current loss: 0.0031725293956696987\n",
      "Current loss: 0.003536930773407221\n",
      "Current loss: 0.012322671711444855\n",
      "Current loss: 0.0032207737676799297\n",
      "Current loss: 0.0033184781204909086\n",
      "Current loss: 0.0023687502834945917\n",
      "Loss min: 0.0006088912487030029, max: 0.10288645327091217, mean: 0.0160243879907066\n",
      "\n",
      "\n",
      "Final mean after 1 runs: 0.016024388372898102\n"
     ]
    }
   ],
   "source": [
    "def make_sun_upperleft(num_channels):\n",
    "    size = 28\n",
    "    xx, yy = np.meshgrid(np.arange(size)-(size-1)/2.,np.arange(size)-(size-1)/2)\n",
    "    r = np.sqrt(xx*xx+yy*yy) \n",
    "    R = np.random.rand(1)*(size/3)\n",
    "    channels = []\n",
    "    for c in range(num_channels):\n",
    "        I_c = R**(c/10.)\n",
    "        channels.append(np.exp(-(r*r)/(R*R))*I_c)\n",
    "    image = torch.cat([torch.from_numpy(channel).float().to(device) for channel in channels]).view(num_channels, 28, 28)\n",
    "    return image\n",
    "\n",
    "means = np.zeros((experiments_count,), dtype=np.float32)\n",
    "for experiment in range(1, experiments_count + 1):\n",
    "    print('\\n\\n----- Experiment Run {}'.format(experiment))\n",
    "    debug_out = True if experiment == 1 else False\n",
    "    means[experiment - 1] = run_experiment(\"upperleft_mean\", make_sun_upperleft)\n",
    "\n",
    "print('\\n\\nFinal mean after {} runs: {}'.format(experiments_count, means.mean()))\n",
    "upperleft_mean = means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Experiment Run 1\n",
      "input_channels: 5\n",
      "cnn_output_dim: 512\n",
      "Current loss: 0.06922677159309387\n",
      "Current loss: 0.06961312144994736\n",
      "Current loss: 0.054807327687740326\n",
      "Current loss: 0.07923974096775055\n",
      "Current loss: 0.04642622917890549\n",
      "Current loss: 0.0594700463116169\n",
      "Current loss: 0.016917988657951355\n",
      "Current loss: 0.0711243525147438\n",
      "Current loss: 0.037444159388542175\n",
      "Current loss: 0.025039231404662132\n",
      "Current loss: 0.029074776917696\n",
      "Current loss: 0.013614590279757977\n",
      "Current loss: 0.03144332766532898\n",
      "Current loss: 0.04383586719632149\n",
      "Current loss: 0.025008097290992737\n",
      "Current loss: 0.03514987230300903\n",
      "Current loss: 0.03891180083155632\n",
      "Current loss: 0.03536498546600342\n",
      "Current loss: 0.029582198709249496\n",
      "Current loss: 0.030439991503953934\n",
      "Current loss: 0.034645527601242065\n",
      "Current loss: 0.02032366953790188\n",
      "Current loss: 0.01586952805519104\n",
      "Current loss: 0.02354850247502327\n",
      "Current loss: 0.0184490829706192\n",
      "Current loss: 0.030492598190903664\n",
      "Current loss: 0.026276033371686935\n",
      "Current loss: 0.035567499697208405\n",
      "Current loss: 0.022682934999465942\n",
      "Current loss: 0.0429106205701828\n",
      "Current loss: 0.02110135555267334\n",
      "Current loss: 0.026342010125517845\n",
      "Current loss: 0.00928474497050047\n",
      "Current loss: 0.011637487448751926\n",
      "Current loss: 0.014829643070697784\n",
      "Current loss: 0.0272317286580801\n",
      "Current loss: 0.024877237156033516\n",
      "Current loss: 0.011771751567721367\n",
      "Current loss: 0.04006944224238396\n",
      "Current loss: 0.016989126801490784\n",
      "Current loss: 0.019124362617731094\n",
      "Current loss: 0.021690385416150093\n",
      "Current loss: 0.0186512041836977\n",
      "Current loss: 0.011847796849906445\n",
      "Current loss: 0.017686763778328896\n",
      "Current loss: 0.010651104152202606\n",
      "Current loss: 0.017001597210764885\n",
      "Current loss: 0.028859037905931473\n",
      "Current loss: 0.017617294564843178\n",
      "Current loss: 0.016650499776005745\n",
      "Current loss: 0.03173627331852913\n",
      "Current loss: 0.02898060902953148\n",
      "Current loss: 0.01369534619152546\n",
      "Current loss: 0.01428682915866375\n",
      "Current loss: 0.014833450317382812\n",
      "Current loss: 0.011004344560205936\n",
      "Current loss: 0.012181028723716736\n",
      "Current loss: 0.04185023158788681\n",
      "Current loss: 0.017946410924196243\n",
      "Current loss: 0.020175348967313766\n",
      "Current loss: 0.018403062596917152\n",
      "Current loss: 0.011476458981633186\n",
      "Current loss: 0.043573055416345596\n",
      "Current loss: 0.010770904831588268\n",
      "Current loss: 0.02242634817957878\n",
      "Current loss: 0.01538611389696598\n",
      "Current loss: 0.011511148884892464\n",
      "Current loss: 0.007921278476715088\n",
      "Current loss: 0.016685519367456436\n",
      "Current loss: 0.0059611983597278595\n",
      "Current loss: 0.011112754233181477\n",
      "Current loss: 0.014808094128966331\n",
      "Current loss: 0.05437289923429489\n",
      "Current loss: 0.011484703049063683\n",
      "Current loss: 0.019732166081666946\n",
      "Current loss: 0.01509022992104292\n",
      "Current loss: 0.014912568032741547\n",
      "Current loss: 0.015792693942785263\n",
      "Current loss: 0.010733174160122871\n",
      "Current loss: 0.02474595606327057\n",
      "Current loss: 0.007138049695640802\n",
      "Current loss: 0.013247047550976276\n",
      "Current loss: 0.020224306732416153\n",
      "Current loss: 0.027452867478132248\n",
      "Current loss: 0.01059247087687254\n",
      "Current loss: 0.020458754152059555\n",
      "Current loss: 0.026191210374236107\n",
      "Current loss: 0.015367795713245869\n",
      "Current loss: 0.01615646481513977\n",
      "Current loss: 0.0069988928735256195\n",
      "Current loss: 0.013894426636397839\n",
      "Current loss: 0.014149253256618977\n",
      "Current loss: 0.03791448473930359\n",
      "Current loss: 0.013445021584630013\n",
      "Current loss: 0.01037870068103075\n",
      "Current loss: 0.01719188690185547\n",
      "Current loss: 0.034247368574142456\n",
      "Current loss: 0.01804138720035553\n",
      "Current loss: 0.007161200046539307\n",
      "Current loss: 0.05874211713671684\n",
      "Loss min: 0.003903792705386877, max: 0.12037217617034912, mean: 0.02662580880243331\n",
      "\n",
      "\n",
      "Final mean after 1 runs: 0.02662580832839012\n"
     ]
    }
   ],
   "source": [
    "def make_sun_lowerleft(num_channels):\n",
    "    size = 28\n",
    "    xx, yy = np.meshgrid(np.arange(size)-(size-1)/2.,np.arange(size)-(size-1)/2)\n",
    "    r = np.sqrt(xx*xx+yy*yy) \n",
    "    R = np.random.rand(1)*(size/3)\n",
    "    channels = []\n",
    "    for c in range(num_channels):\n",
    "        random_channel = np.random.randint(num_channels)\n",
    "        I_c = R ** (random_channel/10.)\n",
    "        channels.append(np.exp(-(r*r)/(R*R))*I_c)\n",
    "    image = torch.cat([torch.from_numpy(channel).float().to(device) for channel in channels]).view(num_channels, 28, 28)\n",
    "    return image\n",
    "\n",
    "means = np.zeros((experiments_count,), dtype=np.float32)\n",
    "for experiment in range(1, experiments_count + 1):\n",
    "    print('\\n\\n----- Experiment Run {}'.format(experiment))\n",
    "    means[experiment - 1] = run_experiment(\"lowerleft_mean\", make_sun_lowerleft)\n",
    "\n",
    "print('\\n\\nFinal mean after {} runs: {}'.format(experiments_count, means.mean()))\n",
    "lowerleft_mean = means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Experiment Run 1\n",
      "input_channels: 5\n",
      "cnn_output_dim: 512\n",
      "Current loss: 0.0765712782740593\n",
      "Current loss: 0.1059737429022789\n",
      "Current loss: 0.07782874256372452\n",
      "Current loss: 0.05921696871519089\n",
      "Current loss: 0.07240017503499985\n",
      "Current loss: 0.041355229914188385\n",
      "Current loss: 0.048635151237249374\n",
      "Current loss: 0.06493006646633148\n",
      "Current loss: 0.05666493624448776\n",
      "Current loss: 0.0234952662140131\n",
      "Current loss: 0.027211377397179604\n",
      "Current loss: 0.03809904307126999\n",
      "Current loss: 0.01515947561711073\n",
      "Current loss: 0.016481712460517883\n",
      "Current loss: 0.029352694749832153\n",
      "Current loss: 0.02614155411720276\n",
      "Current loss: 0.01824517920613289\n",
      "Current loss: 0.019479308277368546\n",
      "Current loss: 0.04191465675830841\n",
      "Current loss: 0.02025655470788479\n",
      "Current loss: 0.013337614946067333\n",
      "Current loss: 0.04049711301922798\n",
      "Current loss: 0.011936454102396965\n",
      "Current loss: 0.02240028791129589\n",
      "Current loss: 0.030952852219343185\n",
      "Current loss: 0.01975098066031933\n",
      "Current loss: 0.03427368029952049\n",
      "Current loss: 0.023930678144097328\n",
      "Current loss: 0.025583883747458458\n",
      "Current loss: 0.031913526356220245\n",
      "Current loss: 0.012260991148650646\n",
      "Current loss: 0.012924619019031525\n",
      "Current loss: 0.010287106968462467\n",
      "Current loss: 0.02047034725546837\n",
      "Current loss: 0.0121312802657485\n",
      "Current loss: 0.03154797479510307\n",
      "Current loss: 0.014019936323165894\n",
      "Current loss: 0.009096241556107998\n",
      "Current loss: 0.014897087588906288\n",
      "Current loss: 0.008548975922167301\n",
      "Current loss: 0.008122192695736885\n",
      "Current loss: 0.013869928196072578\n",
      "Current loss: 0.049556490033864975\n",
      "Current loss: 0.007948486134409904\n",
      "Current loss: 0.0077126286923885345\n",
      "Current loss: 0.03314725682139397\n",
      "Current loss: 0.03952351212501526\n",
      "Current loss: 0.02712986432015896\n",
      "Current loss: 0.012928694486618042\n",
      "Current loss: 0.014450189657509327\n",
      "Current loss: 0.0131571339443326\n",
      "Current loss: 0.013255554251372814\n",
      "Current loss: 0.012957309372723103\n",
      "Current loss: 0.01386725902557373\n",
      "Current loss: 0.007124468684196472\n",
      "Current loss: 0.043577369302511215\n",
      "Current loss: 0.013996437191963196\n",
      "Current loss: 0.016653504222631454\n",
      "Current loss: 0.017617788165807724\n",
      "Current loss: 0.017660411074757576\n",
      "Current loss: 0.014904807321727276\n",
      "Current loss: 0.031607192009687424\n",
      "Current loss: 0.02352699264883995\n",
      "Current loss: 0.06283789873123169\n",
      "Current loss: 0.016053859144449234\n",
      "Current loss: 0.007657831069082022\n",
      "Current loss: 0.04324464127421379\n",
      "Current loss: 0.006779637187719345\n",
      "Current loss: 0.014598583802580833\n",
      "Current loss: 0.03157336264848709\n",
      "Current loss: 0.0069202883169054985\n",
      "Current loss: 0.029369261115789413\n",
      "Current loss: 0.010261883959174156\n",
      "Current loss: 0.008186680264770985\n",
      "Current loss: 0.007935767993330956\n",
      "Current loss: 0.01761823706328869\n",
      "Current loss: 0.007270279340445995\n",
      "Current loss: 0.008252089843153954\n",
      "Current loss: 0.007968856953084469\n",
      "Current loss: 0.016277287155389786\n",
      "Current loss: 0.008214826695621014\n",
      "Current loss: 0.011184616945683956\n",
      "Current loss: 0.007492882199585438\n",
      "Current loss: 0.009450608864426613\n",
      "Current loss: 0.006263358052819967\n",
      "Current loss: 0.011688669212162495\n",
      "Current loss: 0.02798323705792427\n",
      "Current loss: 0.01238306611776352\n",
      "Current loss: 0.0046715992502868176\n",
      "Current loss: 0.012369283474981785\n",
      "Current loss: 0.00993865355849266\n",
      "Current loss: 0.013700531795620918\n",
      "Current loss: 0.01770722307264805\n",
      "Current loss: 0.031077608466148376\n",
      "Current loss: 0.0077168941497802734\n",
      "Current loss: 0.008595901541411877\n",
      "Current loss: 0.014176174998283386\n",
      "Current loss: 0.02151947095990181\n",
      "Current loss: 0.017159391194581985\n",
      "Current loss: 0.006099643651396036\n",
      "Loss min: 0.0025272108614444733, max: 0.1059737429022789, mean: 0.02345594069175422\n",
      "\n",
      "\n",
      "Final mean after 1 runs: 0.023455940186977386\n"
     ]
    }
   ],
   "source": [
    "def make_sun_upperright(num_channels):\n",
    "    size = 28\n",
    "    xx, yy = np.meshgrid(np.arange(size)-(size-1)/2.,np.arange(size)-(size-1)/2)\n",
    "    r = np.sqrt(xx*xx+yy*yy) \n",
    "    R = np.random.rand(1)*(size/3)\n",
    "    channels = []\n",
    "    I_0 = np.random.rand() * 1000.\n",
    "    for c in range(num_channels):\n",
    "        I_c = I_0**(c/10.)\n",
    "        channels.append(np.exp(-(r*r)/(R*R))*I_c)\n",
    "    image = torch.cat([torch.from_numpy(channel).float().to(device) for channel in channels]).view(num_channels, 28, 28)\n",
    "    return image\n",
    "\n",
    "means = np.zeros((experiments_count,), dtype=np.float32)\n",
    "for experiment in range(1, experiments_count + 1):\n",
    "    print('\\n\\n----- Experiment Run {}'.format(experiment))\n",
    "    means[experiment - 1] = run_experiment(\"upperright_mean\", make_sun_upperright)\n",
    "\n",
    "print('\\n\\nFinal mean after {} runs: {}'.format(experiments_count, means.mean()))\n",
    "upperright_mean = means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Experiment Run 1\n",
      "input_channels: 5\n",
      "cnn_output_dim: 512\n",
      "Current loss: 0.06039625406265259\n",
      "Current loss: 0.12421365082263947\n",
      "Current loss: 0.06254603713750839\n",
      "Current loss: 0.10228173434734344\n",
      "Current loss: 0.06314274668693542\n",
      "Current loss: 0.1150655522942543\n",
      "Current loss: 0.11408214271068573\n",
      "Current loss: 0.10918557643890381\n",
      "Current loss: 0.06892549246549606\n",
      "Current loss: 0.06825971603393555\n",
      "Current loss: 0.0779995322227478\n",
      "Current loss: 0.04308873042464256\n",
      "Current loss: 0.0677964836359024\n",
      "Current loss: 0.0721682757139206\n",
      "Current loss: 0.07387714087963104\n",
      "Current loss: 0.04736186936497688\n",
      "Current loss: 0.08620809018611908\n",
      "Current loss: 0.0571100227534771\n",
      "Current loss: 0.0541725754737854\n",
      "Current loss: 0.08241866528987885\n",
      "Current loss: 0.06137850135564804\n",
      "Current loss: 0.04617804288864136\n",
      "Current loss: 0.03510366752743721\n",
      "Current loss: 0.12007714807987213\n",
      "Current loss: 0.07618678361177444\n",
      "Current loss: 0.0672118216753006\n",
      "Current loss: 0.0633297935128212\n",
      "Current loss: 0.06488754600286484\n",
      "Current loss: 0.07998466491699219\n",
      "Current loss: 0.062003396451473236\n",
      "Current loss: 0.04237600415945053\n",
      "Current loss: 0.07828499376773834\n",
      "Current loss: 0.10113532841205597\n",
      "Current loss: 0.07593456655740738\n",
      "Current loss: 0.08668170869350433\n",
      "Current loss: 0.03745521977543831\n",
      "Current loss: 0.08867402374744415\n",
      "Current loss: 0.1025446206331253\n",
      "Current loss: 0.04997139424085617\n",
      "Current loss: 0.08389663696289062\n",
      "Current loss: 0.06649358570575714\n",
      "Current loss: 0.06465480476617813\n",
      "Current loss: 0.09338661283254623\n",
      "Current loss: 0.056915294378995895\n",
      "Current loss: 0.06922799348831177\n",
      "Current loss: 0.05189412832260132\n",
      "Current loss: 0.048794619739055634\n",
      "Current loss: 0.05481595918536186\n",
      "Current loss: 0.059518538415431976\n",
      "Current loss: 0.051130056381225586\n",
      "Current loss: 0.07547453790903091\n",
      "Current loss: 0.05204865336418152\n",
      "Current loss: 0.06387291103601456\n",
      "Current loss: 0.055323995649814606\n",
      "Current loss: 0.06376239657402039\n",
      "Current loss: 0.08216248452663422\n",
      "Current loss: 0.06651664525270462\n",
      "Current loss: 0.05670108646154404\n",
      "Current loss: 0.0374511294066906\n",
      "Current loss: 0.08723132312297821\n",
      "Current loss: 0.0706464871764183\n",
      "Current loss: 0.04743997007608414\n",
      "Current loss: 0.054136671125888824\n",
      "Current loss: 0.05843052268028259\n",
      "Current loss: 0.06892295181751251\n",
      "Current loss: 0.03959950804710388\n",
      "Current loss: 0.058373402804136276\n",
      "Current loss: 0.0876651331782341\n",
      "Current loss: 0.06992878019809723\n",
      "Current loss: 0.05503358691930771\n",
      "Current loss: 0.04022568091750145\n",
      "Current loss: 0.0726146548986435\n",
      "Current loss: 0.05450523644685745\n",
      "Current loss: 0.05722877383232117\n",
      "Current loss: 0.09297949075698853\n",
      "Current loss: 0.05794959515333176\n",
      "Current loss: 0.06402890384197235\n",
      "Current loss: 0.03702827915549278\n",
      "Current loss: 0.07378171384334564\n",
      "Current loss: 0.061996567994356155\n",
      "Current loss: 0.08009806275367737\n",
      "Current loss: 0.0556262843310833\n",
      "Current loss: 0.038296569138765335\n",
      "Current loss: 0.056441426277160645\n",
      "Current loss: 0.06057126447558403\n",
      "Current loss: 0.10112588107585907\n",
      "Current loss: 0.04320360720157623\n",
      "Current loss: 0.09839589893817902\n",
      "Current loss: 0.05782439559698105\n",
      "Current loss: 0.06396298110485077\n",
      "Current loss: 0.05609126016497612\n",
      "Current loss: 0.06863429397344589\n",
      "Current loss: 0.07599277794361115\n",
      "Current loss: 0.1283172070980072\n",
      "Current loss: 0.045234136283397675\n",
      "Current loss: 0.05942634493112564\n",
      "Current loss: 0.038676902651786804\n",
      "Current loss: 0.048614803701639175\n",
      "Current loss: 0.04797210544347763\n",
      "Current loss: 0.0696737989783287\n",
      "Loss min: 0.01996070146560669, max: 0.12884913384914398, mean: 0.06568918412551283\n",
      "\n",
      "\n",
      "Final mean after 1 runs: 0.06568918377161026\n"
     ]
    }
   ],
   "source": [
    "def make_sun_lowerright(num_channels):\n",
    "    size = 28\n",
    "    xx, yy = np.meshgrid(np.arange(size)-(size-1)/2.,np.arange(size)-(size-1)/2)\n",
    "    r = np.sqrt(xx*xx+yy*yy) \n",
    "    R = np.random.rand(1)*(size/3)\n",
    "    channels = []\n",
    "    for c in range(num_channels):\n",
    "        random_channel = np.random.randint(num_channels)\n",
    "        random_luminance = np.random.rand() * 1000. \n",
    "        I_c = random_luminance ** (random_channel/10.)\n",
    "        channels.append(np.exp(-(r*r)/(R*R))*I_c)\n",
    "    image = torch.cat([torch.from_numpy(channel).float().to(device) for channel in channels]).view(num_channels, 28, 28)\n",
    "    return image\n",
    "\n",
    "means = np.zeros((experiments_count,), dtype=np.float32)\n",
    "for experiment in range(1, experiments_count + 1):\n",
    "    print('\\n\\n----- Experiment Run {}'.format(experiment))\n",
    "    means[experiment - 1] = run_experiment(\"lowerright_mean\", make_sun_lowerright)\n",
    "\n",
    "print('\\n\\nFinal mean after {} runs: {}'.format(experiments_count, means.mean()))\n",
    "lowerright_mean = means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross correlation YES/Luminance related to size & shape YES: average mean 0.016024388372898102\n",
      "Cross correlation NO /Luminance related to size & shape YES: average mean 0.02662580832839012\n",
      "Cross correlation YES/Luminance related to size & shape NO : average mean 0.023455940186977386\n",
      "Cross correlation NO /Luminance related to size & shape NO : average mean 0.06568918377161026\n"
     ]
    }
   ],
   "source": [
    "print('Cross correlation YES/Luminance related to size & shape YES: average mean {}'.format(upperleft_mean))\n",
    "print('Cross correlation NO /Luminance related to size & shape YES: average mean {}'.format(lowerleft_mean))\n",
    "print('Cross correlation YES/Luminance related to size & shape NO : average mean {}'.format(upperright_mean))\n",
    "print('Cross correlation NO /Luminance related to size & shape NO : average mean {}'.format(lowerright_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
