"""
Copyright
https://github.com/ozan-oktay/Attention-Gated-Networks/models/networks/utils.py#
"""
import torch.nn as nn

class HookBasedFeatureExtractor(nn.Module):
  def __init__(self, submodule, layername, upscale=False):
    super(HookBasedFeatureExtractor, self).__init__()

    self.submodule = submodule
    self.submodule.eval()
    self.layername = layername
    self.outputs_size = None
    self.outputs = None
    self.inputs = None
    self.inputs_size = None
    self.upscale = upscale

  def get_input_array(self, m, i, o):
    if isinstance(i, tuple):
      self.inputs = [i[index].data.clone() for index in range(len(i))]
      self.inputs_size = [input.size() for input in self.inputs]
    else:
      self.inputs = i.data.clone()
      self.inputs_size = self.input.size()
    print('Input Array Size: ', self.inputs_size)

  def get_output_array(self, m, i, o):
    if isinstance(o, tuple):
      self.outputs = [o[index].data.clone() for index in range(len(o))]
      self.outputs_size = [output.size() for output in self.outputs]
    else:
      self.outputs = o.data.clone()
      self.outputs_size = self.outputs.size()
    print('Output Array Size: ', self.outputs_size)

  def rescale_output_array(self, newsize):
    us = nn.Upsample(size=newsize[2:], mode='bilinear')
    if isinstance(self.outputs, list):
      for index in range(len(self.outputs)): self.outputs[index] = us(self.outputs[index]).data()
    else:
      self.outputs = us(self.outputs).data()

  def forward(self, x):
    target_layer = self.submodule._modules.get(self.layername)

    # Collect the output tensor
    h_inp = target_layer.register_forward_hook(self.get_input_array)
    h_out = target_layer.register_forward_hook(self.get_output_array)
    self.submodule(x)
    h_inp.remove()
    h_out.remove()

    # Rescale the feature-map if it's required
    if self.upscale: self.rescale_output_array(x.size())

    return self.inputs, self.outputs